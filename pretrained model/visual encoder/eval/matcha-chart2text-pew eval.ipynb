{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matcha-chart2text-pew\n",
    "\n",
    "Note\n",
    "- Visual Encoder. Trained on pew dataset\n",
    "- Have similar model but trained with statista dataset\n",
    "- The very first 100 dataset of chartqa is more similar to pew dataset. It is possible that some of the latter part is statista (need to see into it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sung2_8l7o06c\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration\n",
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Pix2StructProcessor.from_pretrained('google/matcha-chart2text-pew')\n",
    "model = Pix2StructForConditionalGeneration.from_pretrained('google/matcha-chart2text-pew').to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Figures/barplot/BarPlot1/Bar0.png'\n",
    "path = \"./autochart\"\n",
    "image = Image.open(path+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just 9% of the public says that part-time workers in the United States are still and likely to be working. That’s up 13 percentage points from 2007, when 9% of the public was1.<0x0A>As it turns out, part-time workers in the United States are still and likely to be working. The public is split over whether this is an all-time high or a “ 55% say20%6%6%6%6%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7%7\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(images=image, text=\"What is this chart about?\", return_tensors=\"pt\").to(0)\n",
    "prediction = model.generate(**inputs, max_new_tokens=512)\n",
    "prediction = processor.decode(prediction[0], skip_special_tokens=True)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "references = json.load(open(path+'/Text description/all_bar_text1.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The bar graph illustrates the number of percentage of part-time workers in luxembourg from 1991 to 1995. Each bar represents the number in the unit of Part-time workers(% of total employed). The number grows from approximately 8 Part-time workers(% of total employed) in 1991 to approximately 11 Part-time workers(% of total employed) in 1995. The number in 1995 being the peak, and the lowest number is recorded in 1991. This unique observation may need some analysis of the related historical events. '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = references[0]['text']\n",
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 6.2856630480765226e-232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sung2_8l7o06c\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\sung2_8l7o06c\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\sung2_8l7o06c\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate import bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Reference sentences (human-generated descriptions)\n",
    "reference_tokens = word_tokenize(reference)\n",
    "\n",
    "# Candidate sentences (textual descriptions generated by the visual encoder)\n",
    "prediction_tokens = word_tokenize(prediction)\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_score = bleu(reference_tokens, prediction_tokens)\n",
    "\n",
    "print(\"BLEU Score:\", bleu_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.08273381294964029, recall=0.27058823529411763, fmeasure=0.12672176308539945)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'])\n",
    "scorer.score(reference, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
    "\n",
    "prediction_embeddings = embed([prediction])[\"outputs\"]\n",
    "reference_embeddings = embed([reference])[\"outputs\"]\n",
    "\n",
    "avg_prediction_embedding = np.mean(prediction_embeddings, axis=0)\n",
    "avg_reference_embedding = np.mean(reference_embeddings, axis=0)\n",
    "\n",
    "similarity_score = cosine_similarity([avg_prediction_embedding], [avg_reference_embedding])[0][0]\n",
    "\n",
    "print(\"Similarity Score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "prediction_embeddings = model.encode(prediction)\n",
    "reference_embeddings = model.encode(reference)\n",
    "\n",
    "avg_prediction_embedding = np.mean(prediction_embeddings, axis=0)\n",
    "avg_reference_embedding = np.mean(reference_embeddings, axis=0)\n",
    "\n",
    "similarity_score = cosine_similarity([avg_prediction_embedding], [avg_reference_embedding])[0][0]\n",
    "\n",
    "print(\"Similarity Score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For multiple evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "\n",
    "scores = []\n",
    "references = json.load(open(path+'/Text description/all_bar_text1.json'))\n",
    "\n",
    "for number in range(1000):\n",
    "    file = f'/Figures/barplot/BarPlot1/Bar{number}.png'\n",
    "    path = \"./autochart\"\n",
    "    image = Image.open(path+file)\n",
    "\n",
    "    inputs = processor(images=image, text=\"What is this chart about?\", return_tensors=\"pt\").to(0)\n",
    "    prediction = model.generate(**inputs, max_new_tokens=512)\n",
    "    prediction = processor.decode(prediction[0], skip_special_tokens=True)\n",
    "\n",
    "    reference = references[number]['text']\n",
    "\n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    prediction_embeddings = model.encode(prediction)\n",
    "    reference_embeddings = model.encode(reference)\n",
    "\n",
    "    avg_prediction_embedding = np.mean(prediction_embeddings, axis=0)\n",
    "    avg_reference_embedding = np.mean(reference_embeddings, axis=0)\n",
    "\n",
    "    similarity_score = cosine_similarity([avg_prediction_embedding], [avg_reference_embedding])[0][0]\n",
    "\n",
    "    scores.append(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
